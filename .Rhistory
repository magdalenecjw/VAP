<<<<<<< HEAD
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1))
#recode dichotomous variables as poLCA expects all variables to start at level 1, hence dichotomous variables should be 1/2 and not 0/1
df_analysis_recoded <- df_analysis %>%
mutate(package_transport_int = recode(package_transport_int,
`1` = 2,
`0` = 1)) %>%
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1))
pacman::p_load(tidyverse)
df <- read_csv("data/touristdata_clean.csv")
df_analysis <- df %>%
select(!ID) %>%
select(!code) %>%
select(!country)
#recode dichotomous variables as poLCA expects all variables to start at level 1, hence dichotomous variables should be 1/2 and not 0/1
df_analysis_recoded <- df_analysis %>%
mutate(package_transport_int = recode(package_transport_int,
`1` = 2,
`0` = 1)) %>%
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1))
shiny::runApp('ShinyDashboard')
View(df_analysis_recoded)
## select variables
##Variables in parentheses are the latent class classification variables.
##Variables outside of the parentheses are covariates (not included in the LCA).
f_nocovariate <- as.formula(cbind(age_group, travel_with, purpose, info_source, tour_arrangement,total_night_spent)~1)
f_wcovariate <- as.formula(cbind(age_group, travel_with, purpose, info_source, tour_arrangement,total_night_spent)~1)
# latent class analysis specifying 1-3 classes
lCA1 <- poLCA(f_nocovariate,df_analysis_recoded, nclass=1,nrep=15)
pacman::p_load(poLCA)
# latent class analysis specifying 1-3 classes
lCA1 <- poLCA(f_nocovariate,df_analysis_recoded, nclass=1,nrep=15)
colnames(df_analysis_recoded)
pacman::p_load(tidyverse)
df <- read_csv("data/touristdata_clean.csv")
df_clustering <- df %>%
select(!code) %>%
select(!country)
pacman::p_load(poLCA, tidyverse)
df <- read_csv("data/touristdata_clean.csv")
df_clustering <- df %>%
select(!code) %>%
select(!country)
#recode dichotomous variables as poLCA expects all variables to start at level 1, hence dichotomous variables should be 1/2 and not 0/1
df_clustering_recoded <- df_clustering %>%
mutate(package_transport_int = recode(package_transport_int,
`1` = 2,
`0` = 1)) %>%
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1))
##ensure all variables are factors
df_clustering_recoded[-1] <- lapply(df_clustering_recoded[-1], factor)
##ensure no missing values
sapply(df_clustering_recoded, function(x) sum(is.na(x)))
## select variables
##Variables in parentheses are the latent class classification variables.
##Variables outside of the parentheses are covariates (not included in the LCA).
f_nocovariate <- as.formula(cbind(total_cost, region, age_group,
travel_with, total_tourist, purpose,
main_activity, info_source,tour_arrangement,
total_night_spent, prop_night_spent_mainland,
payment_mode, first_trip_tz, most_impressing)
~1)
f_wcovariate <- as.formula(cbind(age_group, travel_with, total_tourist,
purpose, main_activity, info_source,
tour_arrangement, total_night_spent,
prop_night_spent_mainland, payment_mode,
first_trip_tz, most_impressing)
~total_cost+region)
##subset the data to only include these selected variables
df_clustering_subset <- df_clustering_recoded %>%
select(ID, total_cost, region, age_group, travel_with, total_tourist,
purpose, main_activity, info_source,tour_arrangement,
total_night_spent, prop_night_spent_mainland, payment_mode,
first_trip_tz, most_impressing)
View(df_clustering_subset)
##latent class analysis specifying 3 classes
##the more classes and variables there are, the longer it takes to run
##can consider limiting the nclass to between 2-10
##if nrep = 1 means local search, if nrep > 1 = global search (running model nrep times) for lowest BIC; consider just checkbox of local vs. global search (global we auto set to nrep = 5)
lCA1 <- poLCA(f_nocovariate, df_clustering_subset, nclass=3, nrep=1)
View(df_clustering_subset)
#recode dichotomous variables as poLCA expects all variables to start at level 1, hence dichotomous variables should be 1/2 and not 0/1
df_clustering_recoded <- df_clustering %>%
mutate(package_transport_int = recode(package_transport_int,
`1` = 2,
`0` = 1)) %>%
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1)) %>%
mutate(duration = cut(total_night_spent, breaks = c(0, 7, Inf),
labels = c("Within_1_week", "More_than_1_week")))
##ensure all variables are factors
df_clustering_recoded[-1] <- lapply(df_clustering_recoded[-1], factor)
##ensure no missing values
sapply(df_clustering_recoded, function(x) sum(is.na(x)))
## select variables
##Variables in parentheses are the latent class classification variables.
##Variables outside of the parentheses are covariates (not included in the LCA).
f_nocovariate <- as.formula(cbind(total_cost, region, age_group,
travel_with, purpose, main_activity,
info_source,tour_arrangement,
duration, prop_night_spent_mainland,
payment_mode, first_trip_tz, most_impressing)
~1)
f_wcovariate <- as.formula(cbind(age_group, travel_with, purpose,
main_activity, info_source, tour_arrangement,
duration, prop_night_spent_mainland,
payment_mode, first_trip_tz, most_impressing)
~total_cost+region)
##subset the data to only include these selected variables
df_clustering_subset <- df_clustering_recoded %>%
select(ID, total_cost, region, age_group, travel_with, purpose,
main_activity, info_source,tour_arrangement, duration,
prop_night_spent_mainland, payment_mode, first_trip_tz,
most_impressing)
View(df_clustering_subset)
View(df_clustering)
## select variables
##Variables in parentheses are the latent class classification variables.
##Variables outside of the parentheses are covariates (not included in the LCA).
f_nocovariate <- as.formula(cbind(total_cost, region, age_group,
travel_with, purpose, main_activity,
info_source,tour_arrangement,
duration, mainland_zanzibar, payment_mode,
first_trip_tz, most_impressing)
~1)
f_wcovariate <- as.formula(cbind(age_group, travel_with, purpose,
main_activity, info_source, tour_arrangement,
duration, mainland_zanzibar, payment_mode,
first_trip_tz, most_impressing)
~total_cost+region)
##subset the data to only include these selected variables
df_clustering_subset <- df_clustering_recoded %>%
select(ID, total_cost, region, age_group, travel_with, purpose,
main_activity, info_source,tour_arrangement, duration,
mainland_zanzibar, payment_mode, first_trip_tz,
most_impressing)
#recode dichotomous variables as poLCA expects all variables to start at level 1, hence dichotomous variables should be 1/2 and not 0/1
df_clustering_recoded <- df_clustering %>%
mutate(package_transport_int = recode(package_transport_int,
`1` = 2,
`0` = 1)) %>%
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1)) %>%
mutate(duration = cut(total_night_spent, breaks = c(0, 7, Inf),
labels = c("Within_1_week", "More_than_1_week"))) %>%
mutate(mainland_zanzibar = cut(prop_night_spent_mainland,
breaks = c(0, 0.5, Inf),
labels = c("zanzibar", "mainland")))
##ensure all variables are factors
df_clustering_recoded[-1] <- lapply(df_clustering_recoded[-1], factor)
##ensure no missing values
sapply(df_clustering_recoded, function(x) sum(is.na(x)))
#recode dichotomous variables as poLCA expects all variables to start at level 1, hence dichotomous variables should be 1/2 and not 0/1
df_clustering_recoded <- df_clustering %>%
mutate(package_transport_int = recode(package_transport_int,
`1` = 2,
`0` = 1)) %>%
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1)) %>%
mutate(duration = cut(total_night_spent, breaks = c(0, 7, Inf),
labels = c("Within_1_week", "More_than_1_week"))) %>%
mutate(mainland_zanzibar = cut(prop_night_spent_mainland,
breaks = c(0, 0.5, 1),
labels = c("zanzibar", "mainland")))
##ensure all variables are factors
df_clustering_recoded[-1] <- lapply(df_clustering_recoded[-1], factor)
##ensure no missing values
sapply(df_clustering_recoded, function(x) sum(is.na(x)))
View(df_clustering_recoded)
#recode dichotomous variables as poLCA expects all variables to start at level 1, hence dichotomous variables should be 1/2 and not 0/1
df_clustering_recoded <- df_clustering %>%
mutate(package_transport_int = recode(package_transport_int,
`1` = 2,
`0` = 1)) %>%
mutate(package_accomodation = recode(package_accomodation,
`1` = 2,
`0` = 1)) %>%
mutate(package_food = recode(package_food,
`1` = 2,
`0` = 1)) %>%
mutate(package_transport_tz = recode(package_transport_tz,
`1` = 2,
`0` = 1)) %>%
mutate(package_sightseeing = recode(package_sightseeing,
`1` = 2,
`0` = 1)) %>%
mutate(package_insurance = recode(package_insurance,
`1` = 2,
`0` = 1)) %>%
mutate(first_trip_tz = recode(first_trip_tz,
`1` = 2,
`0` = 1)) %>%
mutate(duration = cut(total_night_spent, breaks = c(0, 7, Inf),
labels = c("Within_1_week", "More_than_1_week"))) %>%
mutate(mainland_zanzibar = cut(prop_night_spent_mainland,
breaks = c(0, 0.5, Inf), right = F,
labels = c("zanzibar", "mainland")))
##ensure all variables are factors
df_clustering_recoded[-1] <- lapply(df_clustering_recoded[-1], factor)
##ensure no missing values
sapply(df_clustering_recoded, function(x) sum(is.na(x)))
## select variables
##Variables in parentheses are the latent class classification variables.
##Variables outside of the parentheses are covariates (not included in the LCA).
f_nocovariate <- as.formula(cbind(total_cost, region, age_group,
travel_with, purpose, main_activity,
info_source,tour_arrangement,
duration, mainland_zanzibar, payment_mode,
first_trip_tz, most_impressing)
~1)
f_wcovariate <- as.formula(cbind(age_group, travel_with, purpose,
main_activity, info_source, tour_arrangement,
duration, mainland_zanzibar, payment_mode,
first_trip_tz, most_impressing)
~total_cost+region)
##subset the data to only include these selected variables
df_clustering_subset <- df_clustering_recoded %>%
select(ID, total_cost, region, age_group, travel_with, purpose,
main_activity, info_source,tour_arrangement, duration,
mainland_zanzibar, payment_mode, first_trip_tz,
most_impressing)
## select variables
##Variables in parentheses are the latent class classification variables.
##Variables outside of the parentheses are covariates (not included in the LCA).
f_nocovariate <- as.formula(cbind(total_cost, region, age_group,
travel_with, purpose, main_activity,
info_source,tour_arrangement,
duration, mainland_zanzibar, payment_mode,
first_trip_tz)
~1)
f_wcovariate <- as.formula(cbind(age_group, travel_with, purpose,
main_activity, info_source, tour_arrangement,
duration, mainland_zanzibar, payment_mode,
first_trip_tz)
~total_cost+region)
##subset the data to only include these selected variables
df_clustering_subset <- df_clustering_recoded %>%
select(ID, total_cost, region, age_group, travel_with, purpose,
main_activity, info_source,tour_arrangement, duration,
mainland_zanzibar, payment_mode, first_trip_tz)
## select variables
##Variables in parentheses are the latent class classification variables.
##Variables outside of the parentheses are covariates (not included in the LCA).
f_nocovariate <- as.formula(cbind(total_cost, region, age_group,
travel_with, purpose, main_activity,
tour_arrangement, duration,
mainland_zanzibar, payment_mode,
first_trip_tz)
~1)
f_wcovariate <- as.formula(cbind(age_group, travel_with, purpose,
main_activity, tour_arrangement, duration,
mainland_zanzibar, payment_mode,
first_trip_tz)
~total_cost+region)
##subset the data to only include these selected variables
df_clustering_subset <- df_clustering_recoded %>%
select(ID, total_cost, region, age_group, travel_with, purpose,
main_activity, tour_arrangement, duration,
mainland_zanzibar, payment_mode, first_trip_tz)
##latent class analysis specifying 3 classes
##the more classes and variables there are, the longer it takes to run
##can consider limiting the nclass to between 2-10
##if nrep = 1 means local search, if nrep > 1 = global search (running model nrep times) for lowest BIC; consider just checkbox of local vs. global search (global we auto set to nrep = 5)
lCA1 <- poLCA(f_nocovariate, df_clustering_subset, nclass=3, nrep=1)
poLCA.entropy(lCA1)
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy<-function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA3$posterior, 1, entropy))
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy<-function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA1$posterior, 1, entropy))
LCA3_entropy <- (error_prior - error_post) / error_prior
LCA3_entropy
View(lCA1)
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy <- function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA1$posterior, 1, entropy))
LCA3_entropy <- (error_prior - error_post) / error_prior
LCA3_entropy
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy <- function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA1[["posterior"]], 1, entropy))
LCA3_entropy <- (error_prior - error_post) / error_prior
LCA3_entropy
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy <- function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA1$posterior, 1, entropy))
LCA3_entropy <- (error_prior - error_post) / error_prior
LCA3_entropy
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy <- function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA1$posterior, 1, entropy))
LCA3_entropy <- (error_prior - error_post) / error_prior
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy <- function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA1$posterior, c(1,2), entropy))
LCA3_entropy <- (error_prior - error_post) / error_prior
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy <- function (p) sum(-p*log(p))
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(entropy(lCA1$posterior))
LCA3_entropy <- (error_prior - error_post) / error_prior
# Calculate entropy (3-class mode)l- values closer to 1.0 indicate greater separation of the classes.
entropy <- function (p) {sum(-p*log(p))}
error_prior <- entropy(lCA1$P) # Class proportions
error_post <- mean(apply(lCA1$posterior, 1, entropy))
LCA3_entropy <- (error_prior - error_post) / error_prior
df_clustering_subset$class <- lCA1$predclass
pacman::p_load(poLCA, ggplot2, tidyverse)
df <- read_csv("data/touristdata_clean.csv")
df_clustering <- df %>%
select(!code) %>%
select(!country)
ggplot() + geom_bar(data = df_clustering_subset, aes(x = age_group)) +
facet_wrap(vars(class))
##plotting results
ggplot() + geom_bar(data = df_clustering_subset, aes(x = age_group)) +
facet_wrap(vars(class), ncol = 3)
pacman::p_load(tidyverse, rpart, rpart.plot, sparkline, visNetwork,
caret, ranger, patchwork)
df <- read_csv("data/touristdata_clean.csv")
df_analysis <- df %>%
select(!ID) %>%
select(!code) %>%
select(!country)
#selection of variables as a function here
set.seed(1234)
trainIndex <- createDataPartition(df_analysis$total_cost, p = 0.8,
list = FALSE,
times = 1)
df_train <- df_analysis[trainIndex,]
df_test <- df_analysis[-trainIndex,]
pacman::p_load(tidyverse, rpart, rpart.plot, sparkline, visNetwork,
caret, ranger, patchwork)
set.seed(1234)
trainIndex <- createDataPartition(df_analysis$total_cost, p = 0.8,
list = FALSE,
times = 1)
df_train <- df_analysis[trainIndex,]
df_test <- df_analysis[-trainIndex,]
#can we have an option for whether user wants to do parameter tuning?
#default is simple bootstrap resampling
trctrl <- trainControl(method = "none")
#we can give one other option of (repeated) k-fold cross-validation where they can decide on the k and number of repeats
cvControl <- trainControl(##default of 10, range: 3-50
method = "cv",
number = 10)
repeatcvControl <- trainControl(##default of 10, range: 3-50
method = "repeatedcv",
number = 10,
##default of 3, range: 3-10
repeats = 10)
#actual model
rf_model <- train(total_cost ~ .,
data = df_train,
method = "ranger",
trControl = repeatcvControl,
#trControl (refer to above objects created)
num.trees = 50, #can consider range of 5 to 200 trees
importance = "impurity",
#variable importance computation: "impurity", "permutation"
tuneGrid = data.frame(mtry = sqrt(ncol(df_train)),
min.node.size = 5,
splitrule = "variance")
#splitrule: "variance" (default), "extratrees", "maxstat", "beta"
#min.node.size: default of 5 for regression trees
#mtry: default is square root of number of variables
)
df_test$fit_forest <- predict(rf_model, df_test)
##this is related to the model built above, but can we also have a separate tab where model takes in the other parameters set above, but here we allow for a range of the number of trees. This will allow us to plot the R-squared value vs the number of trees.
##our range can remain at 5-500 but would suggest we limit them to select no more than 100 numbers at one go e.g. 5-105 otherwise it will take very long to run depending on which trControl we choose to use
tree_range <- 5:150
=======
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(initialdtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_initialdtmodel <- predict(initialdtmodel, newdata = df_analysis_test)
pred_initialdtmodel_rmse <- Metrics::rmse(actual = df_analysis_test$total_cost, predicted = pred_initialdtmodel)
# Pruned Model ----------------------------------------------------------
dt_bestcp <- initialdtmodel$cptable[which.min(initialdtmodel$cptable[,"xerror"]),"CP"]
tuneddtmodel <- rpart(
formula = total_cost ~ .,
data = df_analysis_train,
method = "anova",
control = rpart.control(minsplit = 10, maxdepth = 15)
)
pruneddtmodel <- prune(tuneddtmodel, cp = 0.1)
#first visualisation
plotcp(pruneddtmodel)
#second visualisation
formatCurrency(
DT::datatable(pruneddtmodel$cptable,
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(pruneddtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_pruneddtmodel <- predict(pruneddtmodel, newdata = df_analysis_test)
pred_pruneddtmodel_rmse <- Metrics::rmse(actual = df_analysis_test$total_cost, predicted = pred_pruneddtmodel)
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz)) %>%
select()
set.seed(1234)
df_analysis_split <- rsample::initial_split(df_analysis, prop = .7)
df_analysis_train <- rsample::training(df_analysis_split)
df_analysis_test  <- rsample::testing(df_analysis_split)
# Initial Model ----------------------------------------------------------
initialdtmodel <- rpart(
formula = total_cost ~ .,
data = df_analysis_train,
method = "anova",
control = rpart.control(minsplit = 5, cp = 0.005, maxdepth = 10)
)
#first visualisation
plotcp(initialdtmodel)
#second visualisation
formatCurrency(
DT::datatable(initialdtmodel$cptable,
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(initialdtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_initialdtmodel <- predict(initialdtmodel, newdata = df_analysis_test)
pred_initialdtmodel_rmse <- Metrics::rmse(actual = df_analysis_test$total_cost, predicted = pred_initialdtmodel)
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz)) %>%
select()
set.seed(1234)
df_analysis_split <- rsample::initial_split(df_analysis, prop = .7)
df_analysis_train <- rsample::training(df_analysis_split)
df_analysis_test  <- rsample::testing(df_analysis_split)
# Initial Model ----------------------------------------------------------
initialdtmodel <- rpart(
formula = total_cost ~ .,
data = df_analysis_train,
method = "anova",
control = rpart.control(minsplit = 5, cp = 0.005, maxdepth = 10)
)
#first visualisation
plotcp(initialdtmodel)
#second visualisation
formatCurrency(
DT::datatable(initialdtmodel$cptable,
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(initialdtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_initialdtmodel <- predict(initialdtmodel, newdata = df_analysis_test)
View(df_analysis)
pacman::p_load("tmap", "ExPanDaR", "kableExtra", "ggstatsplot", "plotly", "DT", "scales","tidyverse")
touristdata_clean <- read_csv("data/touristdata_clean.csv")
library("rsample")
library("Metrics")
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz)) %>%
select()
set.seed(1234)
df_analysis_split <- rsample::initial_split(df_analysis, prop = .7)
df_analysis_train <- rsample::training(df_analysis_split)
df_analysis_test  <- rsample::testing(df_analysis_split)
# Initial Model ----------------------------------------------------------
initialdtmodel <- rpart(
formula = total_cost ~ .,
data = df_analysis_train,
method = "anova",
control = rpart.control(minsplit = 5, cp = 0.005, maxdepth = 10)
)
#first visualisation
plotcp(initialdtmodel)
#second visualisation
formatCurrency(
DT::datatable(initialdtmodel$cptable,
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(initialdtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_initialdtmodel <- predict(initialdtmodel, newdata = df_analysis_test)
pred_initialdtmodel_rmse <- Metrics::rmse(actual = df_analysis_test$total_cost, predicted = pred_initialdtmodel)
# Pruned Model ----------------------------------------------------------
dt_bestcp <- initialdtmodel$cptable[which.min(initialdtmodel$cptable[,"xerror"]),"CP"]
tuneddtmodel <- rpart(
formula = total_cost ~ .,
data = df_analysis_train,
method = "anova",
control = rpart.control(minsplit = 10, maxdepth = 15)
)
pruneddtmodel <- prune(tuneddtmodel, cp = 0.1)
#first visualisation
plotcp(pruneddtmodel)
#second visualisation
formatCurrency(
DT::datatable(pruneddtmodel$cptable,
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(pruneddtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_pruneddtmodel <- predict(pruneddtmodel, newdata = df_analysis_test)
pred_pruneddtmodel_rmse <- Metrics::rmse(actual = df_analysis_test$total_cost, predicted = pred_pruneddtmodel)
View(df_analysis)
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz)) %>%
select()
View(df_analysis)
View(touristdata_clean)
View(touristdata_clean)
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz)) %>%
select()
set.seed(1234)
df_analysis_split <- rsample::initial_split(df_analysis, prop = .7)
df_analysis_train <- rsample::training(df_analysis_split)
df_analysis_test  <- rsample::testing(df_analysis_split)
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz))
set.seed(1234)
df_analysis_split <- rsample::initial_split(df_analysis, prop = .7)
df_analysis_train <- rsample::training(df_analysis_split)
df_analysis_test  <- rsample::testing(df_analysis_split)
# Initial Model ----------------------------------------------------------
initialdtmodel <- rpart(
formula = total_cost ~ .,
data = df_analysis_train,
method = "anova",
control = rpart.control(minsplit = 5, cp = 0.005, maxdepth = 10)
)
#first visualisation
plotcp(initialdtmodel)
#second visualisation
formatCurrency(
DT::datatable(initialdtmodel$cptable,
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(initialdtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_initialdtmodel <- predict(initialdtmodel, newdata = df_analysis_test)
pred_initialdtmodel_rmse <- Metrics::rmse(actual = df_analysis_test$total_cost, predicted = pred_initialdtmodel)
# Pruned Model ----------------------------------------------------------
dt_bestcp <- initialdtmodel$cptable[which.min(initialdtmodel$cptable[,"xerror"]),"CP"]
tuneddtmodel <- rpart(
formula = total_cost ~ .,
data = df_analysis_train,
method = "anova",
control = rpart.control(minsplit = 10, maxdepth = 15)
)
pruneddtmodel <- prune(tuneddtmodel, cp = 0.1)
#first visualisation
plotcp(pruneddtmodel)
#second visualisation
formatCurrency(
DT::datatable(pruneddtmodel$cptable,
rownames = FALSE,
class = "compact"),
c(1,3,4,5), currency = '',
digits = 3)
#third visualisation
visTree(pruneddtmodel, edgesFontSize = 14, nodesFontSize = 16, width = "100%")
#fourth visualisation
pred_pruneddtmodel <- predict(pruneddtmodel, newdata = df_analysis_test)
pred_pruneddtmodel_rmse <- Metrics::rmse(actual = df_analysis_test$total_cost, predicted = pred_pruneddtmodel)
runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
pacman::p_load("tmap", "ExPanDaR", "kableExtra", "ggstatsplot", "plotly", "DT", "scales","tidyverse")
touristdata_clean <- read_csv("data/touristdata_clean.csv")
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
filter(total_cost > 0,
total_tourist > 0,
total_night_spent > 0) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz))
librry("rsample")
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
filter(total_cost > 0,
total_tourist > 0,
total_night_spent > 0) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz))
set.seed(1234)
dt_dataset_split <- initial_split(df_analysis, prop = .7)
dt_dataset_train <- training(dt_dataset_split)
dt_dataset_test  <- testing(dt_dataset_split)
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
filter(total_cost > 0,
total_tourist > 0,
total_night_spent > 0) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz))
set.seed(1234)
dt_dataset_split <- rsample::initial_split(df_analysis, prop = .7)
dt_dataset_train <- rsample::training(dt_dataset_split)
dt_dataset_test  <- rsample::testing(dt_dataset_split)
library("rpart")
initialdtmodel <- rpart(
formula = total_cost ~ .,
data    = dt_dataset_train,
method  = "anova"
)
pred_initialdtmodel <- predict(initialdtmodel, newdata = dt_dataset_test)
dt_predvsactual_initial <- data.frame(actual = dt_dataset_test$total_cost,
pred = pred_initialdtmodel)
View(dt_predvsactual_initial)
ggplot(dt_predvsactual_initial,
aes(actual, pred)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
theme_minimal() +
labs(x = "actual value", y = "predicted value")
shiny::runApp('ShinyDashboard')
pacman::p_load("tmap", "ExPanDaR", "kableExtra", "ggstatsplot", "plotly", "DT", "scales","tidyverse")
touristdata_clean <- read_csv("data/touristdata_clean.csv")
library("rpart")
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
filter(total_cost > 0,
total_tourist > 0,
total_night_spent > 0) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz))
set.seed(1234)
dt_indices <- createDataPartition(df_analysis$total_cost, p =0.7, list = FALSE)
dt_indices <- caret::createDataPartition(df_analysis$total_cost, p =0.7, list = FALSE)
dt_indices <- caret::createDataPartition(df_analysis$total_cost, p =0.7, list = FALSE)
install.packages("caret")
install.packages("caret")
install.packages("caret")
library("caret")
library("rpart")
df_analysis <- touristdata_clean %>%
select(!ID) %>%
select(!code) %>%
select(!country) %>%
filter(total_cost > 0,
total_tourist > 0,
total_night_spent > 0) %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(11:17, as.factor)) %>%
mutate(first_trip_tz = as.factor(first_trip_tz))
set.seed(1234)
dt_indices <- caret::createDataPartition(df_analysis$total_cost, p =0.7, list = FALSE)
dt_indices <- caret::createDataPartition(df_analysis$total_cost, p =0.7, list = FALSE)
dt_dataset_train <- df_analysis[dt_indices,]
dt_dataset_test <- df_analysis[-dt_indices,]
initialdtmodel <- rpart(
formula = total_cost ~ .,
data    = dt_dataset_train,
method  = "anova"
)
pred_initialdtmodel <- predict(initialdtmodel, newdata = dt_dataset_test)
dt_predvsactual_initial <- data.frame(actual = dt_dataset_test$total_cost,
pred = pred_initialdtmodel)
ggplot(dt_predvsactual_initial,
aes(actual, pred)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red") +
theme_minimal() +
labs(x = "Actual Value", y = "Predicted Value")
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
runApp('ShinyDashboard')
pacman::p_load(tidyverse, rpart, rpart.plot, sparkline, visNetwork,
caret, ranger, patchwork, tidyverse, xgboost)
df <- read_csv("data/touristdata_clean.csv")
df_analysis <- df %>%
select(!ID) %>%
select(!code) %>%
select(!country)
#selection of variables as a function here
set.seed(1234)
trainIndex <- createDataPartition(df_analysis$total_cost, p = 0.8,
list = FALSE,
times = 1)
df_train <- df_analysis[trainIndex,]
df_test <- df_analysis[-trainIndex,]
#can we have an option for whether user wants to do parameter tuning?
#default is simple bootstrap resampling
trctrl <- trainControl(method = "none")
#we can give one other option of (repeated) k-fold cross-validation where they can decide on the k and number of repeats
cvControl <- trainControl(##default of 10, range: 3-50
method = "cv",
number = 10)
repeatcvControl <- trainControl(##default of 10, range: 3-50
method = "repeatedcv",
number = 10,
##default of 3, range: 3-10
repeats = 10)
#actual model
rf_model <- train(total_cost ~ .,
data = df_train,
method = "ranger",
trControl = repeatcvControl,
#trControl (refer to above objects created)
num.trees = 50, #can consider range of 5 to 500 trees
importance = "impurity",
#variable importance computation: "impurity", "permutation"
tuneGrid = data.frame(mtry = sqrt(ncol(df_train)),
min.node.size = 5,
splitrule = "variance")
#splitrule: "variance" (default), "extratrees", "maxstat", "beta"
#min.node.size: default of 5 for regression trees
#mtry: default is square root of number of variables
)
df_test$fit_forest <- predict(rf_model, df_test)
rf_scatter <- ggplot() +
geom_point(aes(x = df_test$total_cost, y = df_test$fit_forest)) +
labs(x = "Actual Total Cost", y = "Predicted Total Cost",
title = paste0("R-squared: ", round(rf_model$finalModel$r.squared, digits=2))) +
theme(axis.text = element_text(size = 5),
axis.title = element_text(size = 8),
title = element_text(size = 8))
rf_residuals <- ggplot() +
geom_point(aes(x = df_test$total_cost,
y = (df_test$fit_forest-df_test$total_cost)),
col="blue3") +
labs(y ="Residuals (Predicted-Actual)", x = "Actual Total Cost") +
geom_hline(yintercept = 0, col="red4", linetype = "dashed", linewidth = 0.5) +
theme(axis.text = element_text(size = 5),
axis.title = element_text(size = 8))
p <- rf_scatter + rf_residuals +
plot_annotation(title = "Scatterplot of predicted vs. actual total cost",
theme = theme(plot.title = element_text(size = 18)))
p
#top 20 variable importance
#can we show a title for this table based on what was selected in the model i.e. impurity vs permutation
varImp(rf_model)
##this is related to the model built above, but can we also have a separate tab where model takes in the other parameters set above, but here we allow for a range of the number of trees. This will allow us to plot the R-squared value vs the number of trees.
##our range can remain at 5-500 but would suggest we limit them to select no more than 100 numbers at one go e.g. 5-105 otherwise it will take very long to run depending on which trControl we choose to use
tree_range <- 5:100
>>>>>>> c170a44e73fbc3238d542848a86ebcf6c2c61d51
rsquared_trees <- c()
for (i in tree_range){
rf_model <- train(total_cost ~ .,
data = df_train,
method = "ranger",
<<<<<<< HEAD
trControl = trctrl,
=======
trControl = cvControl,
>>>>>>> c170a44e73fbc3238d542848a86ebcf6c2c61d51
num.trees = i,
importance = "impurity",
tuneGrid = data.frame(mtry = sqrt(ncol(df_train)),
min.node.size = 5,
splitrule = "variance"))
rsquared_trees <- append(rsquared_trees, rf_model$finalModel$r.squared)
}
rsquared_plot <- data.frame(tree_range, rsquared_trees)
ggplot(df = rsquared_plot) +
geom_point(aes(x = tree_range, y = rsquared_trees)) +
labs(x = "Number of trees", y = "R-squared values",
title = "R-squared vs. Number of Trees Plot")
<<<<<<< HEAD
=======
runApp('ShinyDashboard')
##this is related to the model built above, but can we also have a separate tab where model takes in the other parameters set above, but here we allow for a range of the number of trees. This will allow us to plot the R-squared value vs the number of trees.
##our range can remain at 5-500 but would suggest we limit them to select no more than 100 numbers at one go e.g. 5-105 otherwise it will take very long to run depending on which trControl we choose to use
tree_range <- 5:25
rsquared_trees <- c()
for (i in tree_range){
rf_model <- train(total_cost ~ .,
data = df_train,
method = "ranger",
trControl = cvControl,
num.trees = i,
importance = "impurity",
tuneGrid = data.frame(mtry = sqrt(ncol(df_train)),
min.node.size = 5,
splitrule = "variance"))
rsquared_trees <- append(rsquared_trees, rf_model$finalModel$r.squared)
}
rsquared_plot <- data.frame(tree_range, rsquared_trees)
ggplot(df = rsquared_plot) +
geom_point(aes(x = tree_range, y = rsquared_trees)) +
labs(x = "Number of trees", y = "R-squared values",
title = "R-squared vs. Number of Trees Plot")
#top 20 variable importance
#can we show a title for this table based on what was selected in the model i.e. impurity vs permutation
varImp(rf_model)
##this is related to the model built above, but can we also have a separate tab where model takes in the other parameters set above, but here we allow for a range of the number of trees. This will allow us to plot the R-squared value vs the number of trees.
##our range can remain at 5-500 but would suggest we limit them to select no more than 100 numbers at one go e.g. 5-105 otherwise it will take very long to run depending on which trControl we choose to use
tree_range <- 5:25
rsquared_trees <- c()
for (i in tree_range){
rf_model <- train(total_cost ~ .,
data = df_train,
method = "ranger",
trControl = cvControl,
num.trees = i,
importance = "impurity",
tuneGrid = data.frame(mtry = sqrt(ncol(df_train)),
min.node.size = 5,
splitrule = "variance"))
rsquared_trees <- append(rsquared_trees, rf_model$finalModel$r.squared)
}
rsquared_plot <- data.frame(tree_range, rsquared_trees)
ggplot(df = rsquared_plot) +
geom_point(aes(x = tree_range, y = rsquared_trees)) +
labs(x = "Number of trees", y = "R-squared values",
title = "R-squared vs. Number of Trees Plot")
runApp('ShinyDashboard')
runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
runApp('ShinyDashboard')
runApp('ShinyDashboard')
runApp('ShinyDashboard')
caret::RMSE(pred_initialdtmodel, dt_dataset_test$total_cost)
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
shiny::runApp('ShinyDashboard')
runApp('ShinyDashboard')
runApp('ShinyDashboard')
runApp('ShinyDashboard')
runApp('ShinyDashboard')
pacman::p_load(poLCA, ggplot2, tidyverse)
df <- read_csv("data/touristdata_clean.csv")
df_clustering <- df %>%
select(!code) %>%
select(!country)
install.packages("poLCA")
>>>>>>> c170a44e73fbc3238d542848a86ebcf6c2c61d51
